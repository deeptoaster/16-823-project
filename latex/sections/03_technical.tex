\section{Method}\label{sec:technical}
\subsection{Photometric Stereo With Multiple Lights}
In the original formulation of photometric stereo~\cite{woodham1979}, a minimum
of $N \ge 3$ frames of an diffuse object are captured. The lighting of a single
frame $1 \le i \le N$ is assumed to come from a single directional source
$\light_i$, where $\hat{\light}_i = \frac{\light_i}{\|\light_i\|}$ is the
vector pointing in the direction of the source (opposite the incoming rays) and
$\|\light_i\|$ is its intensity. Then, for each pixel of value $\pixel_i$ that
images a point on the object with surface normal $\hat{\point}$ and albedo
$\albedo$,
\begin{equation}
  \pixel_i = \light_i^\intercal \rho \hat{\point}
\end{equation}
If, instead of a single light, we have $L$ sources possibly incident on the
point in a single frame, this becomes
\begin{equation} \label{eq:photometric-stereo}
  \pixel_i = \rho \sum_{j = 1}^L \occlusion_{j, i} \light_{j, i}^\intercal \hat{\point}
           = \left(\sum_{j = 1}^L \occlusion_{j, i} \light_{j, i}^\intercal\right) \rho \hat{\point}
\end{equation}
as the sum of the contribution of each source $1 \le j \le L$. Here,
$\occlusion_{j, i}$ is an indicator of whether light from source $j$ contacts the
point or is occluded. As in the original formulation, the problem is
underconstrained unless there are at least $N \ge 3$ \emph{captures} of each
pixel, with $\light_i$ not all coplanar and each nonzero (i.e., not with all
lights involved occluded). 

Let $\tilde{\light}_i = \sum_{j = 1}^L \occlusion_{j, i} \light_{j, i}$ and
$\point = \rho \hat{\point}$ for brevity. Then
Equation~\ref{eq:photometric-stereo} can be written as a system of linear
equations that can be solved with least-squares methods, allowing us to recover
albedo and surface normal for each pixel:
\begin{align}
  \begin{bmatrix}
    \pixel_1 \\
    \vdots \\
    \pixel_N
  \end{bmatrix}             &= \begin{bmatrix}
    \tilde{\light}_1^\intercal \\
    \vdots \\
    \tilde{\light}_N^\intercal
  \end{bmatrix} \point \\
  \pixels                   &= \lights \point \\
  \lights^\intercal \pixels &= \lights^\intercal \lights \point \\
  \point                    &= {\left(\lights^\intercal \lights\right)}^{-1} \lights^\intercal \pixels
\end{align}
Continuity assumptions can then be used to recover a depth map of the scene
from the computed surface normals.
\subsection{Mirror Relationships}
A scene with one directional light and one plane mirror can be analyzed as one
with two lights that are related to each other by reflection across the mirror
plane.

Ignoring optical properties such as polarization, light arriving on the object
surface after reflecting off a perfect mirror from the direct source is
indistinguishable from light arriving from the image of the source across the
mirror plane. That is, the vector $\light_{j, i}'$ pointing from the surface to
the image of the light source can be expressed as
\begin{equation}
  \light_i' = \light_i - 2 \light_i^\parallel
            = \light_i - 2 \left(\light_i^\intercal \mirror\right) \mirror
\end{equation}
where $\mirror$ is the unit normal of the fixed scene mirror. This means that the
light from the source and mirror in a single frame can be
combined as
\begin{equation}
  \tilde{\light}_i = \occlusion_i \light_i + \occlusion_i' \light_i'
                   = \begin{cases}
    \light_i                                                       & \textrm{mirror occluded} \\
    \light_i - 2 \left(\light_i^\intercal \mirror\right) \mirror   & \textrm{direct occluded} \\
    2 \light_i - 2 \left(\light_i^\intercal \mirror\right) \mirror & \textrm{neither occluded} \\
    0                                                              & \textrm{both occluded}
  \end{cases}
\end{equation}
The $\tilde{\light}_i = 0$ case is the easiest to detect, as it results in a
zero-valued pixel under ideal conditions. To address this situation, we can
either take a sufficiently large number $N$ of captures and ignore the ones
that result in a zero value for any given pixel, or use shape or shading
regularization techniques with a sparse linear solver as in~\cite{hernandez}.
We ignore such cases for now, with the hope that we are able to place the light
source or mirror in such a way that either the direct light source or its
reflection reaches every pixel of interest on the image.
\begin{figure}\label{fig:light-reflection}
  \includesvg[width=\columnwidth]{images/light-reflection.svg}
  \caption{The light incident on the object from a directional source reflected
  across a mirror is analyzed as light from the image of the source. Note that
  arrows point in the direction of the vectors used in the algorithm, not in
  the direction of light travel. Vector lengths are not to scale.}
\end{figure}
\subsection{Computing Normals and Depth}
For the other three cases, we compute $\point$ nine times, one for each case
for each of three captures. By assumping the normal $\hat{\point} =
\frac{\point}{\|\point\|}$ varies smoothly across large regions of the object
(its faces), we associate candidates of $\point(x, y)$ with likely candidates
$\point(x \pm 1, y)$ and $\point(x, y \pm 1)$ of its neighbors, forming a graph
whose connected components correspond to faces of the object.  For a given
pixel position $(x, y)$, we take the candidate $\point$ that belongs to the
largest connected component and use it to recover $z$ according to the standard
depth-from-normal algorithm.

Another consideration in our system is that some of the pixels captured may
image a mirror reflection of the object, rather than a point on the object
directly. We account for this by pre-segmenting the part of the capture that
images the mirror and constructing a virtual camera position---the image of the
actual camera position reflected across the mirror plane---and using it to
separately perform photometric stereo on the reflected scene. Note that unlike
with the directional light source, we cannot assume the camera, whether
orthographic or projective, to be infinitely distant from the scene. Therefore,
a slightly different virtual camera is required for every pixel captured.

One final requirement of photometric stereo is that the lighting directions not
be coplanar. In our case, the requirement is on $\tilde{\light}_i$. With a
fixed mirror, this reduces to the standard condition that the direct lighting
directions $\light_i$ not be coplanar.
